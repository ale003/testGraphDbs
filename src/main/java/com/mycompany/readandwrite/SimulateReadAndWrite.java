/*
 * To change this license header, choose License Headers in Project Properties.
 * To change this template file, choose Tools | Templates
 * and open the template in the editor.
 */
package com.mycompany.readandwrite;

import java.io.PrintWriter;
import java.util.ArrayList;
import java.util.Iterator;
import java.util.Map;
import java.util.logging.Level;
import java.util.logging.Logger;
import org.openrdf.model.Model;
import org.openrdf.model.impl.LinkedHashModel;
import org.openrdf.model.vocabulary.FOAF;
import org.openrdf.model.vocabulary.RDF;
import org.openrdf.model.vocabulary.RDFS;
import org.openrdf.model.vocabulary.XMLSchema;
import org.openrdf.repository.RepositoryException;
import org.openrdf.repository.RepositoryResult;
import org.openrdf.repository.sail.SailRepository;
import org.openrdf.rio.RDFFormat;
import org.openrdf.rio.Rio;

/**
 *
 * @author Admin
 */
public class SimulateReadAndWrite extends Thread {

    private GraphDbTesting _graphDbTest;
    public SailRepository rep;
    public String outputFileName;

    public long lastCommitTime;
    public int Nstatements;
    public String outputName;
    public String graphDbUsed;
    public String keyspace;
    public String currentNamespace = "http://www.ontorion.com/testontology.owl#";

    private int _NelementsFinal;
    private int _step;
    private Thread _thread;
    private boolean _stopped = false;
    private boolean _finished = false;
    private boolean _started = false;
    private boolean _error = false;
    private int _NelementsCurrent = 0;
    private boolean _skipReadingAndWriteOutputToFile = false;
    private int[] QUERYINDEXES = new int[]{2, 3, 4, 5, 6, 7};

    /// <summary>
    ///  Class to simulate both read and write for a generic repository. 
    /// </summary>
    /// <param name="rep">RDF repository to use</param>
    /// <param name="Nelements">Number of elements to be generated by the simulation.</param>
    /// <param name="readStep">Number of element to load in the repository before each read.</param>
    /// <param name="commitBufferSize">Number of element to load before commiting the changes to the Repository.</param>
    public SimulateReadAndWrite(SailRepository repExt, String outputNameExt, int Nelements, int readStep, int commitBufferSize, String graphDbUsedExt, String keyspaceExt, String currentNameSpace, boolean skipReading) throws RepositoryException {
        if (currentNameSpace != null) {
            this.currentNamespace = currentNameSpace;
        }

        outputName = outputNameExt;
        rep = repExt;
        _graphDbTest = new GraphDbTesting(rep, this.currentNamespace);
        _graphDbTest.commitBufferSize = commitBufferSize;
        _NelementsFinal = Nelements;
        _step = readStep;
        graphDbUsed = graphDbUsedExt;
        keyspace = keyspaceExt;
        _skipReadingAndWriteOutputToFile = skipReading;
        outputFileName = "";
    }

    public void SkipReadingAndSaveOutputToFile(String outputFileNameExt) {
        _skipReadingAndWriteOutputToFile = true;
        outputFileName = outputFileNameExt;
    }

    /// <summary>
    /// same work of startProcess but asyncronously
    /// </summary>
    public void run() {
        if (_started) {
            return;
        }

        _finished = _stopped = _error = false;

        PrintWriter swrWrites = null;
        PrintWriter swrReads = null;
        PrintWriter logInfo = null;

        try {

            swrWrites = new PrintWriter(outputName + "AllWrites.csv");
            swrWrites.write("Ntriples,CommitTime (ms)\n");

            swrReads = new PrintWriter(outputName + "AllReads.csv");

            String line = "Ntriples,Ntrials";

            for (int i = 0; i < QUERYINDEXES.length; i++) {
                int qu = QUERYINDEXES[i];
                line += ",Mean Query" + qu + "(ms), Std Query" + qu + "(ms), Nres Query" + qu;
            }
            swrReads.println(line);

            logInfo = new PrintWriter(outputName + "LogInfo.txt");
        } catch (Exception ex) {
            return;
        }

        try {
            for (int i = _step; i < _NelementsFinal + 1; i += _step) {
                if (!_stopped) {
                    Work(logInfo, swrWrites, swrReads, i);
                } else {
                    _finished = true;
                    _started = false;
                    //throw new OperationCanceledException("My job was canceled after processing " + i + " elements.");
                }
                _NelementsCurrent = i;
            }

            if (!_stopped && _skipReadingAndWriteOutputToFile) {
                RepositoryResult statements = rep.getConnection().getStatements(null, null, null, true);

                Model model = new LinkedHashModel();

                //               model.addAll(new java.util.ArrayList(statements));
                java.util.ArrayList arr = new java.util.ArrayList();
                while (statements.hasNext()) {
                    arr.add(statements.next());
                }
                model.addAll(arr);

                //Model model = Iterations.addAll(statements, new LinkedHashModel());
                model.setNamespace("rdf", RDF.NAMESPACE);
                model.setNamespace("rdfs", RDFS.NAMESPACE);
                model.setNamespace("xsd", XMLSchema.NAMESPACE);
                model.setNamespace("foaf", FOAF.NAMESPACE);
                model.setNamespace("ex", "");

                Rio.write(model, new java.io.FileWriter(new java.io.File(outputFileName)), RDFFormat.TURTLE);
            }

            Close();
        } catch (Exception ex) {
            _error = true;
            logInfo.write("########################## AN ERROR OCCURED IN THE THREAD!\n");

            logInfo.write(ex.getMessage());
            logInfo.write(ex.getStackTrace().toString());
        } finally {
            _finished = true;
            _started = false;
            swrReads.close();
            swrWrites.close();
            logInfo.close();

        }
        _started = true;
    }

    /// <summary>
    /// stop the current process. It will before wait for the process to finish one iteration and then stop it.
    /// </summary>
    public void StopProcess() {
        _stopped = true;
    }

    /// <summary>
    /// return true if the process started has been completed
    /// </summary>
    /// <returns></returns>
    public boolean IsProcessCompleted() {
        return _finished;
    }

    /// <summary>
    /// Give the process status
    /// </summary>
    /// <returns></returns>
    public String GetProcessStatus() {
        boolean processCompleted = IsProcessCompleted();

        if (_error == true) {
            return "Error";
        } else if (_stopped == true && processCompleted) {
            return "Stopped by the user";
        } else if (_stopped == true && !processCompleted) {
            return "Stopping";
        } else if (!processCompleted) {
            return "Working";
        } else {
            return "Completed";
        }

    }

    /// <summary>
    /// give the percentage of process completed
    /// </summary>
    /// <returns></returns>
    public double GetProgress() {
        return (double) (100 * ((double) _NelementsCurrent / (double) _NelementsFinal));
    }

    /// <summary>
    /// do the write and then the read until it has generated all the Elements.
    /// </summary>
    /// <param name="swrWrites"></param>
    /// <param name="swrReads"></param>
    public void Work(PrintWriter logInfo, PrintWriter swrWrites, PrintWriter swrReads, int el) {
        logInfo.write("Nelements:" + el + "...Writing\n");
        int offset = el - _step;
        writeTiming(logInfo, swrWrites, el, offset);
        swrWrites.flush();
        if (!_skipReadingAndWriteOutputToFile) {
            logInfo.write("Nelements:" + el + "...Writing\n");
            readTiming(logInfo, swrReads, 10);
            swrReads.flush();
        }
    }

    /// <summary>
    /// timing for various write configurations
    /// </summary>
    public void writeTiming(PrintWriter logInfo, PrintWriter swr, int Narticles, int offset) {
        try {
            logInfo.write("Writing....\n");
            // standard configurations
            Map<Integer, Long> commitTime = _graphDbTest.testWrite(logInfo, Narticles, offset);
            
            // write log....
            long tmpCommitTime = 0;
            
            Iterator iter = commitTime.keySet().iterator();
            while (iter.hasNext()) {
                Integer key = (Integer) iter.next();
                Long val = (Long) commitTime.get(key);
                swr.println(String.format("%d,%d", key, val + lastCommitTime));
                tmpCommitTime = val;
                Nstatements = key;
            }
            
            lastCommitTime += tmpCommitTime;
        } catch (Exception ex) {
            Logger.getLogger(SimulateReadAndWrite.class.getName()).log(Level.SEVERE, null, ex);
        }
    }

    /// <summary>
    /// timing for various read configurations
    /// </summary>
    public void readTiming(PrintWriter logInfo, PrintWriter swr, int Ntrials) {
        // standard configurations
        ArrayList<StdMeasures> measures = new ArrayList<StdMeasures>();

        for (int i = 0; i < QUERYINDEXES.length; i++) {
            int que = QUERYINDEXES[i];
            measures.add(_graphDbTest.testRead(logInfo, que, Ntrials,false,"logInfo.txt"));
        }

        // write log
        String outp = Nstatements + "," + Ntrials;
        for (int i = 0; i < measures.size(); i++) {
            StdMeasures stdMe = measures.get(i);
            outp += String.format(",%.2f,%.2f,%d", stdMe.Mean, stdMe.Std, stdMe.Nres);
        }
        swr.println(outp);
    }

    public void Close() {
        try {
            _graphDbTest.CloseAllConnections();
        } catch (RepositoryException ex) {
            Logger.getLogger(SimulateReadAndWrite.class.getName()).log(Level.SEVERE, null, ex);
        }
    }
}
