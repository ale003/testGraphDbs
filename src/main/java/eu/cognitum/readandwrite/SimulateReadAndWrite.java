// ============================================================================================================== 
// Â© 2014 Cognitum. All rights reserved.  
//
// Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance  
// with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 
// Unless required by applicable law or agreed to in writing, software distributed under the License is  
// distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  
// See the License for the specific language governing permissions and limitations under the License. 
// ============================================================================================================== 
package eu.cognitum.readandwrite;

import java.io.PrintWriter;
import java.util.ArrayList;
import java.util.Iterator;
import java.util.Map;
import java.util.logging.Level;
import java.util.logging.Logger;
import org.openrdf.model.Model;
import org.openrdf.model.impl.LinkedHashModel;
import org.openrdf.model.vocabulary.FOAF;
import org.openrdf.model.vocabulary.RDF;
import org.openrdf.model.vocabulary.RDFS;
import org.openrdf.model.vocabulary.XMLSchema;
import org.openrdf.repository.RepositoryException;
import org.openrdf.repository.RepositoryResult;
import org.openrdf.repository.sail.SailRepository;
import org.openrdf.rio.RDFFormat;
import org.openrdf.rio.Rio;

/**
 * Thread used to execute the generation of the RDF graph, writing it on the db
 * and reading using sparql.
 *
 * @author Alessandro Seganti (Data Engineer @Cognitum)
 * @version     0.0
 * @since       2014-04-10
 * @copyright Cognitum, Poland 2014 
 */
public class SimulateReadAndWrite extends Thread {

    private GraphDbTesting _graphDbTest;
    public SailRepository rep;
    public String outputFileName;

    public long lastCommitTime;
    public int Nstatements;
    public String outputName;
    public String graphDbUsed;
    public String keyspace;
    public String currentNamespace = "http://www.ontorion.com/testontology.owl#";

    private int _NelementsFinal;
    private int _step;
    private Thread _thread;
    private boolean _stopped = false;
    private boolean _finished = false;
    private boolean _started = false;
    private boolean _error = false;
    private int _NelementsCurrent = 0;
    private boolean _skipReadingAndWriteOutputToFile = false;
    private int[] QUERYINDEXES = new int[]{2, 3, 4, 5, 6, 7};

    /**
     * Class to simulate both read and write for a generic repository.
     * @param repExt RDF repository to use
     * @param Nelements Number of elements to be generated by the
     * simulation.
     * @param readStep Number of element to load in the repository before
     * each read.
     * @param commitBufferSize Number of element to load before commiting
     * the changes to the Repository.
     */
    public SimulateReadAndWrite(SailRepository repExt, String outputNameExt, int Nelements, int readStep, int commitBufferSize, String graphDbUsedExt, String keyspaceExt, String currentNameSpace, boolean skipReading) throws RepositoryException {
        if (currentNameSpace != null) {
            this.currentNamespace = currentNameSpace;
        }

        outputName = outputNameExt;
        rep = repExt;
        _graphDbTest = new GraphDbTesting(rep, this.currentNamespace);
        _graphDbTest.commitBufferSize = commitBufferSize;
        _NelementsFinal = Nelements;
        _step = readStep;
        graphDbUsed = graphDbUsedExt;
        keyspace = keyspaceExt;
        _skipReadingAndWriteOutputToFile = skipReading;
        outputFileName = "";
    }

    public void SkipReadingAndSaveOutputToFile(String outputFileNameExt) {
        _skipReadingAndWriteOutputToFile = true;
        outputFileName = outputFileNameExt;
    }

    /**
     * same work of startProcess but asyncronously
     */
    public void run() {
        if (_started) {
            return;
        }

        _finished = _stopped = _error = false;

        PrintWriter swrWrites = null;
        PrintWriter swrReads = null;
        PrintWriter logInfo = null;

        try {

            swrWrites = new PrintWriter(outputName + "AllWrites.csv");
            swrWrites.write("Ntriples,CommitTime (ms)\n");

            swrReads = new PrintWriter(outputName + "AllReads.csv");

            String line = "Ntriples,Ntrials";

            for (int i = 0; i < QUERYINDEXES.length; i++) {
                int qu = QUERYINDEXES[i];
                line += ",Mean Query" + qu + "(ms), Std Query" + qu + "(ms), Nres Query" + qu;
            }
            swrReads.println(line);

            logInfo = new PrintWriter(outputName + "LogInfo.txt");

            for (int i = _step; i < _NelementsFinal + 1; i += _step) {
                if (!_stopped) {
                    Work(logInfo, swrWrites, swrReads, i);
                } else {
                    _finished = true;
                    _started = false;
                    //throw new OperationCanceledException("My job was canceled after processing " + i + " elements.");
                }
                _NelementsCurrent = i;
            }

            if (!_stopped && _skipReadingAndWriteOutputToFile) {
                RepositoryResult statements = rep.getConnection().getStatements(null, null, null, true);

                Model model = new LinkedHashModel();

                //               model.addAll(new java.util.ArrayList(statements));
                java.util.ArrayList arr = new java.util.ArrayList();
                while (statements.hasNext()) {
                    arr.add(statements.next());
                }
                model.addAll(arr);

                //Model model = Iterations.addAll(statements, new LinkedHashModel());
                model.setNamespace("rdf", RDF.NAMESPACE);
                model.setNamespace("rdfs", RDFS.NAMESPACE);
                model.setNamespace("xsd", XMLSchema.NAMESPACE);
                model.setNamespace("foaf", FOAF.NAMESPACE);
                model.setNamespace("ex", "");

                Rio.write(model, new java.io.FileWriter(new java.io.File(outputFileName)), RDFFormat.TURTLE);
            }

            Close();
        } catch (Exception ex) {
            _error = true;
            logInfo.write("########################## AN ERROR OCCURED IN THE THREAD!\n");

            logInfo.write(ex.getMessage());
            logInfo.write(ex.getStackTrace().toString());
        } finally {
            _finished = true;
            _started = false;
            swrReads.close();
            swrWrites.close();
            logInfo.close();

        }
        _started = true;
    }

    /**
     * stop the current process. It will before wait for the process to finish
     * one iteration and then stop it.
     */
    public void StopProcess() {
        _stopped = true;
    }

    /**
     * return true if the process started has been completed
     */
    public boolean IsProcessCompleted() {
        return _finished;
    }

    /**
     * Give the process status
     */
    public String GetProcessStatus() {
        boolean processCompleted = IsProcessCompleted();

        if (_error == true) {
            return "Error";
        } else if (_stopped == true && processCompleted) {
            return "Stopped by the user";
        } else if (_stopped == true && !processCompleted) {
            return "Stopping";
        } else if (!processCompleted) {
            return "Working";
        } else {
            return "Completed";
        }

    }

    /**
     * give the percentage of process completed
     */
    public double GetProgress() {
        return (double) (100 * ((double) _NelementsCurrent / (double) _NelementsFinal));
    }

    /**
     * do the write and then the read until it has generated all the Elements.
     * @param swrWrites stream where to write write info 
     * @param swrReads stream where to write read info
     * @param logInfo stream where to write log info
     * @param el Number of elements
     */
    public void Work(PrintWriter logInfo, PrintWriter swrWrites, PrintWriter swrReads, int el) throws Exception {
        logInfo.write("Nelements:" + el + "...Writing\n");
        int offset = el - _step;
        writeTiming(logInfo, swrWrites, el, offset);
        swrWrites.flush();
        if (!_skipReadingAndWriteOutputToFile) {
            logInfo.write("Nelements:" + el + "...Writing\n");
            readTiming(logInfo, swrReads, 10);
            swrReads.flush();
        }
    }

    /**
     * timing for various write configurations
     */
    public void writeTiming(PrintWriter logInfo, PrintWriter swr, int Narticles, int offset) throws Exception {
        logInfo.write("Writing....\n");
        // standard configurations
        Map<Integer, Long> commitTime = _graphDbTest.testWrite(logInfo, Narticles, offset);

        // write log....
        long tmpCommitTime = 0;

        Iterator iter = commitTime.keySet().iterator();
        while (iter.hasNext()) {
            Integer key = (Integer) iter.next();
            Long val = (Long) commitTime.get(key);
            swr.println(String.format("%d,%d", key, val + lastCommitTime));
            tmpCommitTime = val;
            Nstatements = key;
        }

        lastCommitTime += tmpCommitTime;
    }

    /**
     * timing for various read configurations
     */
    public void readTiming(PrintWriter logInfo, PrintWriter swr, int Ntrials) {
        // standard configurations
        ArrayList<StdMeasures> measures = new ArrayList<StdMeasures>();

        for (int i = 0; i < QUERYINDEXES.length; i++) {
            int que = QUERYINDEXES[i];
            measures.add(_graphDbTest.testRead(logInfo, que, Ntrials, false, "logInfo.txt"));
        }

        // write log
        String outp = Nstatements + "," + Ntrials;
        for (int i = 0; i < measures.size(); i++) {
            StdMeasures stdMe = measures.get(i);
            outp += String.format(",%.2f,%.2f,%d", stdMe.Mean, stdMe.Std, stdMe.Nres);
        }
        swr.println(outp);
    }

    public void Close() {
        try {
            _graphDbTest.CloseAllConnections();
        } catch (RepositoryException ex) {
            Logger.getLogger(SimulateReadAndWrite.class.getName()).log(Level.SEVERE, null, ex);
        }
    }
}
